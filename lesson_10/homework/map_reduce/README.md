# MapReduce

Продолжаем тему MapReduce. Задача будет сложнее, чем подсчет слов в файлах. Нужно прочитать данные из нескольких [csv-файлов](https://ru.wikipedia.org/wiki/CSV).

Четыре таких файла включены в проект:
- data/data_1.csv
- data/data_2.csv
- data/data_3.csv
- data/data_4.csv

Данные выглядят так:

```
1,apples,100,150
2,tomatos,20,10
3,potato,17,230
...
```

Каждая строка содержит 4 значения: номер, название товара, его количество и цена.

Пользователь указывает список файлов. Система должна прочитать эти файлы, распарсить данные, извлечь название товара и его количество. Данные из всех файлов нужно объединить и выдать как ответ пользователю.

Например, если в одном файле у нас:

```
1,apples,100,150
2,tomatos,20,10
```

а в другом:

```
5,apples,120,115
6,potato,77,52
```

то результат должен быть:

```
%{
  "apples" => 220,
  "tomatos" => 20,
  "potato" => 77
}
```

Файл может содержать невалидные данные (см **data/data_4.csv** для примера). Пользователь может указать несуществующий файл. Хорошее решение подразумевает обработку этих ситуаций.


## Решение в одном процессе

Конечно, задачу можно решить в одном процессе, обработав все файлы по очереди. На самом деле, с этого и нужно начать. Это позволит сосредоточиться на бизнес задаче и отделить её от задачи управления процессами.

Проект содержит два модуля: **AnalyseFruitsSP** (Single process solution) и **AnalyseFruitsMP** (MapReduce solution); и два отдельных набора тестов для этих модулей.

Начните с модуля AnalyseFruitsSP и в нем решите задачу в один поток. Это будет несложно. Обработка ошибок для этого решения не требуется, негативных тестов на обработку ошибок нет.


## Решение MapReduce

После того, как у вас есть однопоточное решение, и оно проходит тесты, можно взяться за распараллеливание работы на несколько процессов.


### Построение дерева процессов

Первая трудность, которая вас ожидает -- создание дерева процессов.

В предыдущем примере MapReduce дерево было задано статически:

```elixir
processes_tree = 
{:reducer, :root_reducer, [
    {:reducer, :r1, [
        {:mapper, :w1, "./10_01_processes.md"},
        {:mapper, :w2, "./10_02_mailbox.md"}
      ]},
    {:reducer, :r2, [
        {:mapper, :w3, "./10_03_link.md"},
        {:mapper, :w4, "./10_04_monitor.md"}
      ]}
  ]}
```

Сейчас вы не можете так сделать, потому что не знаете заранее, сколько файлов укажет пользователь. 

Это могут быть 2 файла, и тогда хватит двух mapper и одного reducer. А могут быть 200 файлов, и тогда нужно дерево побольше. Понятно, что на 200 файлов нужно 200 mapper. А сколько нужно reducer? Какая должна быть глубина дерева? Тут неплохо было бы иметь настройку. И у нас есть настройка -- **processes_per_level**. Этот параметр означает, сколько дочерних процессов может быть у одного reducer. 

Количество файлов и настройка processes_per_level полностью определяют структуру дерева. Например, у нас есть 5 файлов и processer_per_level = 3. Тогда дерево будет выглядеть так:

```
- root_reducer
  - reducer, id:1,3
    - mapper, id:1
    - mapper, id:2
    - mapper, id:3
  - reducer: id:4,5
    - mapper: id:4
    - mapper: id:5
```

А с настройкой processer_per_level = 2 дерево станет глубже:

```
- root_reducer
  - reducer, id:1,4
    - reducer, id:1,2
      - mapper, id:1
      - mapper, id:2
    - reducer, id:3,4
      - mapper, id:3
      - mapper, id:4
  - reducer, id:5,5
    - mapper, id:5
```

Процессы mapper и reducer имеют id:

```elixir
@type mapper_id :: integer
@type mapper :: {:mapper, mapper_id, String.t}
@type reducer_id :: {integer, integer}
@type children :: [mapper] | [reducer]
@type reducer :: {:reducer, reducer_id, children}
```

Для mapper это просто число -- номер файла. Для reducer это два числа -- диапазон файлов, который обслуживает данный reducer. 

Функция **AnalyseFruitsMP.build_processes_tree/2** принимает список файлов и настройку и возвращает дерево процессов.

```elixir
  @spec build_processes_tree([String.t], integer) :: reducer
  def build_processes_tree(files, processes_per_level) do
```

Посмотрите тесты на эту функцию, в них вы найдете больше примеров.

Если построение дерева вызвает трудности, попробуйте применить [динамическое программирование](https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D0%BD%D0%B0%D0%BC%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5).


### Сбор и агрегация данных

На этом этапе не должно возникнуть трудностей. Решение у вас уже есть, нужно только разделить его между mapper и reducer.

Если вы будете сравнивать решение двух задач: текущей и задачи из урока (суммирование слов в файлах), то, возможно, вам захочется построить абстракции для mapper и reducer, чтобы обобщить их для разных задач. Я не рекомендую делать это сейчас. Нужные абстракции в Эликсир, конечно же, есть. И мы будем изучать их на следущем уроке.


### Обработка ошибок

Это самый сложный этап, задача со звездочкой. Пришло время научиться обрабатывать ошибки в духе Let It Crash. 

Идея сама по себе проста: если процесс-mapper не может обработать данные по любой причине (невалидный или отсутствующий файл), то mapper просто завершается с ошибкой. Процесс-reducer должен запустить свои дочерние mapper через spawn_link и в цикле reduce обработать не только данные от mappers, но и сообщения о завершении дочерних процессов. Эти сообщения будут в любом случае, завершатся процессы нормально или аварийно.

При любой ошибке в любом mapper конечным результатом должен быть `{:error, reason}`. Есть набор негативных тестов, смотрите, какой результат там ожидается.

Будьте внимательны к циклу receive в процессе консоли, откуда запускается весь анализ. Если mapper и reducer процессы завершаются после обработки данных, то консоль продолжает работать. При нескольких запусках анализа данных в почтовом ящике консоли могут накапливаться необработанные сообщения. И сообщения от предыдущих запусков могут влиять на логику обработки последущих запусков. 
